{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ac4a9e-b213-4f2f-b805-6b01e0ae22f6",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1acf735-4982-47a0-bcb4-2a2e07ce6df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.4\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51822a29-a133-49cf-93b1-afe04308baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install redlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca795339-aeaf-4ee6-8c92-5e040515ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import json\n",
    "import IPython.display\n",
    "import pydantic\n",
    "import random\n",
    "import logging\n",
    "\n",
    "from redlines import Redlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8077b1-2ae9-41fc-a2ec-3c4c2381e2d5",
   "metadata": {},
   "source": [
    "# settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8efec195-5e95-4404-a3f3-36d250b6e211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://192.168.0.211:11434'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:\n",
    "    # host = 'http://192.168.0.59:11434'\n",
    "    host = 'http://192.168.0.211:11434'\n",
    "else:\n",
    "    host = 'http://localhost:11434'\n",
    "host"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37cd97e-81af-40ae-9f01-e62b2de34d41",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82b856e-b583-4674-b143-3d96a406b504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'edited_excerpt': {'title': 'Edited Excerpt',\n",
       "   'type': 'string'},\n",
       "  'comments': {'title': 'Comments', 'type': 'string'},\n",
       "  'rationale': {'title': 'Rationale', 'type': 'string'}},\n",
       " 'required': ['edited_excerpt', 'comments', 'rationale'],\n",
       " 'title': 'book_edit',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class book_edit(pydantic.BaseModel):\n",
    "    edited_excerpt: str\n",
    "    comments: str\n",
    "    rationale: str\n",
    "\n",
    "book_edit.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82ce8f21-2187-4bc7-8efe-04039150bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown(s):\n",
    "    display(IPython.display.Markdown(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca49fec6-6931-48fa-85e3-232aefb750d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_markdown_sections(markdown_text, heading_level=1):\n",
    "    \"\"\"\n",
    "    Split a markdown string into sections based on heading level.\n",
    "    Returns a list of section strings.\n",
    "    \"\"\"\n",
    "    heading_pattern = re.compile(rf'^({\"#\" * heading_level}) (.+)', re.MULTILINE)\n",
    "    matches = list(heading_pattern.finditer(markdown_text))\n",
    "\n",
    "    if not matches:\n",
    "        return [markdown_text]  # No headings, return entire content as one section\n",
    "\n",
    "    sections = []\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        start = match.start()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(markdown_text)\n",
    "        section = markdown_text[start:end].strip()\n",
    "        sections.append(section)\n",
    "\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a476166-ff7b-4e3d-8e23-ed83ff838846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_paragraphs(section_text):\n",
    "    \"\"\"\n",
    "    Splits a markdown section into paragraphs.\n",
    "    Ignores blank lines inside bullet points, quotes, or code blocks.\n",
    "    Returns a list of paragraph strings.\n",
    "    \"\"\"\n",
    "    lines = section_text.splitlines()\n",
    "    paragraphs = []\n",
    "    buffer = []\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        if stripped:\n",
    "            buffer.append(line)\n",
    "        elif buffer:\n",
    "            # End of a paragraph\n",
    "            paragraphs.append('\\n'.join(buffer).strip())\n",
    "            buffer = []\n",
    "\n",
    "    # Catch any remaining paragraph\n",
    "    if buffer:\n",
    "        paragraphs.append('\\n'.join(buffer).strip())\n",
    "\n",
    "    return paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a39a4e89-5f44-45a3-9048-3a660a15deae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deepseek-r1:14b',\n",
       " 'gemma3:12b',\n",
       " 'deepseek-r1:latest',\n",
       " 'gemma3:latest',\n",
       " 'qwen3:latest',\n",
       " 'qwen2.5vl:latest']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ollama_models(host=host):\n",
    "    \"\"\"\n",
    "    Returns a list of installed Ollama model names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{host}/api/tags\")\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        models = [model[\"name\"] for model in data.get(\"models\", [])]\n",
    "        return models\n",
    "    except requests.RequestException as e:\n",
    "        print(\"Error connecting to Ollama:\", e)\n",
    "        return []\n",
    "\n",
    "get_ollama_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b021fc0-baa2-4fbc-82f9-a01eb82b8c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qwen3:latest'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab20981e-1e62-47b6-a076-f73c3a762eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edited_excerpt': 'I enjoy large buttocks.',\n",
       " 'comments': \"Original text was informal and contained slang terms. I replaced 'big' with 'large' for a more neutral tone, and added proper nouns (buttocks) instead of the colloquial term to make it sound less casual while still conveying the same meaning without being crude.\",\n",
       " 'rationale': \"The original phrase is too direct and informal for a professional book editing context. Using standard English terms like 'large buttocks' maintains clarity but elevates the language appropriately.\"}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def edit_text(text, system_prompt=None, model=None, host='http://localhost:11434'):\n",
    "    url = f'{host}/api/generate'\n",
    "    schema = book_edit.model_json_schema()\n",
    "    if system_prompt is None:\n",
    "        system_prompt = (\n",
    "            'You are a professional book editor. Edit the following text for clarity, grammar, and style, '\n",
    "            'and provide comments and rationale for your changes. Return the response in JSON format '\n",
    "            'conforming to this schema:\\n' + json.dumps(schema, indent=2)\n",
    "        )\n",
    "\n",
    "    if model is None:\n",
    "        model = random.choice(get_ollama_models())\n",
    "        \n",
    "    prompt = f\"{system_prompt}\\n\\nText to edit:\\n{text}\"\n",
    "    payload = {\n",
    "        'model': model,\n",
    "        'prompt': prompt,\n",
    "        'stream': False,\n",
    "        'format': schema\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code != 200:\n",
    "        print(response.text)\n",
    "        assert False\n",
    "    result = response.json()['response']\n",
    "    if isinstance(result, str):\n",
    "        result = json.loads(result)\n",
    "    # print(result)\n",
    "    return result\n",
    "\n",
    "# t = queue[0]\n",
    "# edit_text(t, system_prompt, 'qwen2.5vl:7b')\n",
    "\n",
    "edit_text('i like big butts', model='deepseek-r1', host=host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3906682a-8f53-4ea9-9d61-1ffe09832ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_heading_levels_simple(markdown_text, prefix='#'):\n",
    "    \"\"\"\n",
    "    Adds one '#' to the beginning of every Markdown heading line (e.g., # → ##).\n",
    "    \"\"\"\n",
    "    return re.sub(r'^(#{1,6})\\s', prefix + r'\\1 ', markdown_text, flags=re.MULTILINE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c796b26f-76f8-4625-b619-5d1ba5bd9a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_inline_markdown_diff(old_md, new_md):\n",
    "    diff = Redlines(old_md, new_md)\n",
    "    display(IPython.display.Markdown(diff.output_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c604ea0b-bf30-4641-933c-0ebdba4860c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_think_and_rest(text):\n",
    "    # This pattern captures: (1) before <think>, (2) inside <think>, (3) after </think>\n",
    "    match = re.match(r'(.*)<think>(.*?)</think>(.*)', text, flags=re.DOTALL)\n",
    "    if match:\n",
    "        # Combine the parts before and after <think> as 'rest'\n",
    "        rest = match.group(1) + match.group(3)\n",
    "        thinking = match.group(2)\n",
    "        return thinking, rest\n",
    "    else:\n",
    "        # If no <think> block is present\n",
    "        return '', text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9d597-f113-49b7-bedb-976d3464ce44",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417af1b-61fa-4a2a-88e5-a88fae6be231",
   "metadata": {},
   "source": [
    "# ollama_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b31160d-ca90-43f5-b00c-bf30bba73bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deepseek-r1:14b',\n",
       " 'gemma3:12b',\n",
       " 'deepseek-r1:latest',\n",
       " 'qwen3:latest',\n",
       " 'qwen2.5vl:latest']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama_models = get_ollama_models()\n",
    "ignore_list = [\n",
    "    'deepseek-r1:32b',\n",
    "    # 'deepseek-r1:14b',\n",
    "    'deepseek-r1:7b',\n",
    "    'deepseek-r1:1.5b',\n",
    "    'gemma3:27b-it-qat',\n",
    "    'gemma3:12b-it-qat',\n",
    "    # 'gemma3:12b',\n",
    "    'gemma3:1b-it-qat',\n",
    "    'gemma3:1b-it-qat',\n",
    "    'gemma3:latest',\n",
    "    'qwen3:14b',\n",
    "    'hf.co/OuteAI/OuteTTS-0.2-500M-GGUF:Q2_K',\n",
    "    'gemma3:1b-it-qat',\n",
    "]\n",
    "ollama_models = [x for x in ollama_models if x not in ignore_list]\n",
    "ollama_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ab55ce-51d4-4920-a53a-9735ce041655",
   "metadata": {},
   "source": [
    "# system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64231e77-ab91-4a95-8017-50462b126281",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = r'''\n",
    "You are an expert editor refining an adult fantasy novel written in British English, set in a modern-day world where gods, monsters, and mythical creatures coexist with humans. The target audience is adults, and the book includes swearing and sexual references, which are acceptable but must remain tasteful and contextually appropriate. The story follows Aisling, an Investigative agent; Eric, who communicates with spirits; and Maeve, a resurrected woman confronting a demon. Your goal is to enhance the manuscript while preserving its tone, style, and narrative voice. Follow these guidelines:\n",
    "\n",
    "1. **Language and Style**:\n",
    "\n",
    "   - Adhere to British English conventions (e.g., \"colour\" not \"color\", \"organise\" not \"organize\").\n",
    "   - Don't insert a dot after a title, (e.g. \"Mr\" not \"Mr.\")\n",
    "2. **Editing Tasks**:\n",
    "\n",
    "   - Correct grammar, punctuation, and spelling per British English standards (e.g., single quotes for dialogue, consistent Oxford comma use).\n",
    "   - Do not comment on or flag issues related to the plot, including inconsistencies or pacing.\n",
    "   - Do not change the tone.\n",
    "\n",
    "3. **Culture and Genre**:\n",
    "\n",
    "   - Respect British cultural nuances, including modern idioms suitable for an adult audience.\n",
    "   - Ensure reimagined folklore creatures and fantasy elements align with the modern setting and feel fresh, avoiding clichéd tropes.\n",
    "\n",
    "4. **Output Format**:\n",
    "\n",
    "   - Provide edited text with changes marked (e.g., \\[original\\] → \\[edited\\]).\n",
    "   - Include a separate section with concise comments explaining major changes or suggestions, excluding any plot-related feedback.\n",
    "   - For significant rewrites, propose revised text with a brief rationale, focusing on style, language, or setting.\n",
    "\n",
    "5. **Additional Instruction**:\n",
    "\n",
    "   - If no manuscript excerpt is provided, do not generate or edit a sample passage. Wait for further input.\n",
    "\n",
    "Begin editing the provided excerpt, aligning with these guidelines. If no excerpt is provided, do not proceed until further instructions are given.\n",
    "'''\n",
    "# markdown(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdca34f6-f26d-40da-b8ff-adb8f089cb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "You are an expert editor specialising in British English.  \n",
       "Your task is to review the user’s text for correct spelling, grammar according to British English conventions.  \n",
       "Make only the necessary corrections—do not alter the tone, style, or meaning of the original text.  \n",
       "Don't add extra commas.\n",
       "Don't change quotation marks.\n",
       "\n",
       "Return the corrected version only, without explanations or additional comments.\n",
       "\n",
       "---\n",
       "\n",
       "**Example Usage:**\n",
       "\n",
       "> **User:**  \n",
       "> The colour of the neighbours car is grey, but it's tires are flat.\n",
       "\n",
       "> **AI Output:**  \n",
       "> The colour of the neighbour’s car is grey, but its tyres are flat.\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = '''\n",
    "You are an expert editor specialising in British English.  \n",
    "Your task is to review the user’s text for correct spelling, grammar according to British English conventions.  \n",
    "Make only the necessary corrections—do not alter the tone, style, or meaning of the original text.  \n",
    "Don't add extra commas.\n",
    "Don't change quotation marks.\n",
    "\n",
    "Return the corrected version only, without explanations or additional comments.\n",
    "\n",
    "---\n",
    "\n",
    "**Example Usage:**\n",
    "\n",
    "> **User:**  \n",
    "> The colour of the neighbours car is grey, but it's tires are flat.\n",
    "\n",
    "> **AI Output:**  \n",
    "> The colour of the neighbour’s car is grey, but its tyres are flat.\n",
    "\n",
    "\n",
    "'''\n",
    "markdown(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd56f2b4-d06a-4136-8c3b-476196f72656",
   "metadata": {},
   "source": [
    "# read book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "817f69ee-c904-4c52-91e0-131de2838a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('book.md', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2e508b2-6ca9-4f45-9582-71eb6bee37d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections = split_markdown_sections(content)\n",
    "len(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7459e564-3d58-47f0-9527-43b2f58a7bcc",
   "metadata": {},
   "source": [
    "# iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99239e04-00f6-41bb-87fe-78c019468918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['While waiting for her name to be called for her job interview, Aisling Kane pulled out her phone and watched a video of the man who might be her next boss. The video was of a television show that had aired the previous night.',\n",
       " 'The audience clapped as the show started, and the host greeted the viewers. \"Good evening, ladies and gentlemen and welcome to Questions Tonight. I am your host, Phillip Newman, and my guests tonight are, on my left, the leader of the Britain First Party, Mr David Smith.\" There was a short pause for applause as a middle-aged obese man dressed in an ill-fitting dark blue suit with a Union Jack tie smiled and nodded at the audience. His short, bristly grey hair and five o\\'clock shadow made him look dirty and unwashed. The host continued, \"On my right, Sir Frederic Allen of the Department of Education.\" More applause this time for a thin, spectacled gentleman with neat, tidy black hair and a blue tie. He was clean-shaven and smiled uncomfortably. He was, in essence, the very image of a British politician. \"And next to him is Sir Wulfric Cran, Head of the Department of Investigations and Discoveries.\" The audience clapped slightly louder this time as a very tall man stood and bowed to the audience. He flashed a winning white smile that showed a pair of small fangs. His short blonde hair was freshly cut, and his deep blue eyes were hard to look away from. He wore a well-fitted grey suit, a blue shirt and an open collar with no tie. \"Our apologies for the absence of our labour representative. We are assured that an urgent family matter has arisen. So, let us begin with tonight\\'s discussion. Sir Frederic, what is the Government\\'s plan to deal with the increasing number of people suffering from Lycanthropy in this country?\"',\n",
       " '\"Well, Phillip, as the Prime Minister has stated that the home office and immigration departments are investigating to find out how many of those suffering from Lycanthropy are British nationals that have contracted the disease in Britain and how many are citizens of poorer nations that are entering the country, sometimes illegally, to use our treatment centres.\" He responded with the style you\\'d expect from someone who attended the finest school in the country.',\n",
       " 'The host continued, \"But does this government have any plans to slow down the increase in cases and stop a possible outbreak, as it were?\"']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue = []\n",
    "\n",
    "i = 0\n",
    "for section in sections[:3]:\n",
    "    paragraphs = split_into_paragraphs(section)\n",
    "    for paragraph in paragraphs:\n",
    "        queue.append(paragraph)\n",
    "\n",
    "queue = queue[9:13]\n",
    "len(queue)\n",
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b3c452c-5d6e-467b-92a5-e940ac5c1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ba6a0b5-b060-4d01-a87d-e5d3f519f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = queue[0]\n",
    "# edit_text(t, system_prompt, 'qwen2.5vl:7b')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f9c09ef-d5fc-477b-a754-f33d7e56ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit_text(queue[0], system_prompt, 'gemma3:4b-it-qat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b25b992-9ba9-4e96-998c-d2dd5f8883b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma3:4b-it-qat'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = random.choice(ollama_models)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489b222-c77a-4d68-b8d5-9af65c437eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ccd2bb3-7f6e-41d9-854e-b4d284ad862c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Introduction\\n\\nTo my clearly intelligent and undoubtedly attractive reader. I just wanted to say a quick thank you for taking the time to read my work. This is the first book of what will hopefully be a long and (most importantly) fun career.\\n\\nWhile I cannot personally thank all my readers, I can express my gratitude here for giving me your attention for a brief moment in time. Thank you. I sincerely mean that.\\n\\nI’d also like to say thank you to everyone who encouraged and supported me when writing this book. They had to wait many years for me to stop talking about it and actually do it.\\n\\nFinally, I’d like to dedicate this book to my wife. Without her, I wouldn’t even be here at all.\\n\\nThanks again, everyone. Please enjoy.\\n\\nSincerely  \\nTimothy Stormcrow\\n\\nP.S. My wife has just told me that I will be sleeping on the sofa unless I also dedicate the book to my cat Bellatrix. She was no help and hindered my attempts to write this book. But I love her.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sections[0]\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c383742f-93af-4e85-b670-7863dc8cefae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYou are an expert editor specialising in British English.  \\nYour task is to review the user’s text for correct spelling, grammar according to British English conventions.  \\nMake only the necessary corrections—do not alter the tone, style, or meaning of the original text.  \\nDon't add extra commas.\\nDon't change quotation marks.\\n\\nReturn the corrected version only, without explanations or additional comments.\\n\\n---\\n\\n**Example Usage:**\\n\\n> **User:**  \\n> The colour of the neighbours car is grey, but it's tires are flat.\\n\\n> **AI Output:**  \\n> The colour of the neighbour’s car is grey, but its tyres are flat.\\n\\n\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a459086d-7827-40a4-aff9-edcc0bfbe5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edited_excerpt': '# Introduction\\n\\nTo my clearly intelligent and undoubtedly attractive reader, I just wanted to say a quick thank you for taking the time to read my work. This is the first book of what will hopefully be a long and (most importantly) fun career.\\n\\nWhile I cannot personally thank all my readers, I can express my gratitude here for giving me your attention for a brief moment in time. Thank you. I sincerely mean that.\\n\\nI’d also like to say thank you to everyone who encouraged and supported me while writing this book. They had to wait many years for me to stop talking about it and actually do it.\\n\\nFinally, I’d like to dedicate this book to my wife. Without her, I wouldn’t even be here at all.\\n\\nThanks again, everyone. Please enjoy.\\n\\nSincerely,\\nTimothy Stormcrow\\n\\nP.S. My wife has just told me that I will be sleeping on the sofa unless I also dedicate the book to my cat Bellatrix. She was no help and hindered my attempts to write this book. But I love her.',\n",
       " 'comments': 'The original text was somewhat disjointed and lacked proper punctuation and formatting. The edited version improves clarity and readability by adding proper punctuation, formatting, and restructuring some sentences for better flow.',\n",
       " 'rationale': 'The original text was somewhat disjointed and lacked proper punctuation and formatting. The edited version improves clarity and readability by adding proper punctuation, formatting, and restructuring some sentences for better flow. The original text also had some grammatical errors and unnecessary repetition, which were corrected in the edited version. The overall tone of the text was friendly and appreciative, which was maintained in the edited version.'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_text(s, host=host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847e0ec-5507-4a70-be7f-a5338f4d9809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1737e631-1a95-461a-829c-7699c4d447e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### edit"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:red;font-weight:700;text-decoration:line-through;'>While waiting for her name to be called for her job interview, Aisling Kane pulled out her phone and watched a video </span><span style='color:green;font-weight:700;'>The colour </span>of the <span style='color:red;font-weight:700;text-decoration:line-through;'>man who might be her next boss. The video was of a television show that had aired the previous night.</span><span style='color:green;font-weight:700;'>neighbours car is grey, but it's tires are flat.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### comments\n",
       "\n",
       " tyre’s spelling as ‘tyres’ which conforms to British English conventions rather than using American spelling like ‘tire’."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### rationale\n",
       "\n",
       " As an editor specialising in British English, I noticed that the user wrote 'tires' instead of 'tyres'. In British English, we use 'tyres' for the plural form. So I changed it accordingly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def review_text(text, host, system_prompt=None, model=None):\n",
    "    r = edit_text(text, system_prompt, model, host=host)\n",
    "    edited_excerpt = r.get('edited_excerpt', None)\n",
    "    comments = r.get('comments', None)\n",
    "    rationale = r.get('rationale', None)\n",
    "\n",
    "    edit = increase_heading_levels_simple(edited_excerpt, prefix='##')\n",
    "\n",
    "    markdown('### edit')\n",
    "    display_inline_markdown_diff(t, edit)\n",
    "\n",
    "    if comments:\n",
    "        markdown(f'### comments\\n\\n{comments}')\n",
    "\n",
    "    if rationale:\n",
    "        markdown(f'### rationale\\n\\n{rationale}')\n",
    "\n",
    "\n",
    "review_text(s, host=host, system_prompt=system_prompt, model='deepseek-r1:14b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15511541-f7e1-45c1-86ac-de711356b727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## model='gemma3:4b-it-qat'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Unterminated string starting at: line 2 column 21 (char 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m markdown(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m## \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m queue:\n\u001b[0;32m----> 4\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43medit_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     edited_excerpt \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medited_excerpt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     comments \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m, in \u001b[0;36medit_text\u001b[0;34m(text, system_prompt, model, host)\u001b[0m\n\u001b[1;32m     18\u001b[0m result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print(result)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 2 column 21 (char 22)"
     ]
    }
   ],
   "source": [
    "markdown(f'## {model=}')\n",
    "\n",
    "for t in queue:\n",
    "    r = edit_text(t, system_prompt, model)\n",
    "    edited_excerpt = r.get('edited_excerpt', None)\n",
    "    comments = r.get('comments', None)\n",
    "    rationale = r.get('rationale', None)\n",
    "\n",
    "    edit = increase_heading_levels_simple(edited_excerpt, prefix='##')\n",
    "\n",
    "    markdown('### edit')\n",
    "    display_inline_markdown_diff(t, edit)\n",
    "\n",
    "    if comments:\n",
    "        markdown(f'### comments\\n\\n{comments}')\n",
    "\n",
    "    if rationale:\n",
    "        markdown(f'### rationale\\n\\n{rationale}')\n",
    "\n",
    "    markdown('### end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13776fde-4a07-4d7e-b859-33e3be086849",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# markdown(f'## input\\n\\n{increase_heading_levels_simple(section)}')\n",
    "\n",
    "for model in ollama_models[2:]:\n",
    "    markdown(f'## {model=}')\n",
    "\n",
    "    for t in queue:\n",
    "        r = edit_text(t, system_prompt, model)\n",
    "        edited_excerpt = r.get('edited_excerpt', None)\n",
    "        comments = r.get('comments', None)\n",
    "        rationale = r.get('rationale', None)\n",
    "\n",
    "        edit = increase_heading_levels_simple(edited_excerpt, prefix='##')\n",
    "\n",
    "        markdown('### edit')\n",
    "        display_inline_markdown_diff(t, edit)\n",
    "\n",
    "        if comments:\n",
    "            markdown(f'### comments\\n\\n{comments}')\n",
    "\n",
    "        if rationale:\n",
    "            markdown(f'### rationale\\n\\n{rationale}')\n",
    "\n",
    "        markdown('### end')\n",
    "        \n",
    "        # display(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be7e727-2803-4f0b-88b4-3403e0cd227c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
